{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.722384Z",
     "start_time": "2020-11-11T11:39:33.844060Z"
    }
   },
   "outputs": [],
   "source": [
    "#indexer for XML data\n",
    "from __future__ import print_function\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from collections import *\n",
    "import sys\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import os\n",
    "import heapq\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.728370Z",
     "start_time": "2020-11-11T11:39:34.723415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.743538Z",
     "start_time": "2020-11-11T11:39:34.729369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wikidump_0000001.xml', 'wikidump_0000002.xml', 'wikidump_0000003.xml', 'wikidump_0000004.xml', 'wikidump_0000005.xml', 'wikidump_0000006.xml', 'wikidump_0000007.xml', 'wikidump_0000008.xml', 'wikidump_0000009.xml', 'wikidump_0000010.xml', 'wikidump_0000011.xml', 'wikidump_0000012.xml', 'wikidump_0000013.xml', 'wikidump_0000014.xml', 'wikidump_0000015.xml', 'wikidump_0000016.xml', 'wikidump_0000017.xml', 'wikidump_0000018.xml', 'wikidump_0000019.xml', 'wikidump_0000020.xml', 'wikidump_0000021.xml', 'wikidump_0000022.xml', 'wikidump_0000023.xml', 'wikidump_0000024.xml', 'wikidump_0000025.xml', 'wikidump_0000026.xml', 'wikidump_0000027.xml', 'wikidump_0000028.xml', 'wikidump_0000029.xml', 'wikidump_0000030.xml', 'wikidump_0000031.xml', 'wikidump_0000032.xml', 'wikidump_0000033.xml', 'wikidump_0000034.xml', 'wikidump_0000035.xml', 'wikidump_0000036.xml', 'wikidump_0000037.xml', 'wikidump_0000038.xml', 'wikidump_0000039.xml', 'wikidump_0000040.xml', 'wikidump_0000041.xml', 'wikidump_0000042.xml', 'wikidump_0000043.xml', 'wikidump_0000044.xml', 'wikidump_0000045.xml', 'wikidump_0000046.xml', 'wikidump_0000047.xml', 'wikidump_0000048.xml', 'wikidump_0000049.xml', 'wikidump_0000050.xml']\n"
     ]
    }
   ],
   "source": [
    "XML_file_names = os.listdir('current')\n",
    "print(XML_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.751515Z",
     "start_time": "2020-11-11T11:39:34.745531Z"
    }
   },
   "outputs": [],
   "source": [
    "# RE to remove urls\n",
    "regExp1 = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.DOTALL)\n",
    "\n",
    "# RE to remove tags & css\n",
    "regExp2 = re.compile(r'{\\|(.*?)\\|}',re.DOTALL)\n",
    "\n",
    "# Regular Expression to remove {{cite **}} or {{vcite **}}\n",
    "regExp3 = re.compile(r'{{v?cite(.*?)}}',re.DOTALL)\n",
    "\n",
    "# Regular Expression to remove [[file:]]\n",
    "regExp4 = re.compile(r'\\[\\[file:(.*?)\\]\\]',re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.759519Z",
     "start_time": "2020-11-11T11:39:34.753509Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # define the pattern to keep\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \n",
    "    return re.sub(pat, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.769473Z",
     "start_time": "2020-11-11T11:39:34.761491Z"
    }
   },
   "outputs": [],
   "source": [
    "page_cnt = 0\n",
    "\n",
    "text_dic = defaultdict(list)\n",
    "text_cnt_dic ={}\n",
    "\n",
    "category_dic =defaultdict(list)\n",
    "category_cnt_dic ={}\n",
    "\n",
    "infobox_dic =defaultdict(list)\n",
    "infobox_cnt_dic ={}\n",
    "\n",
    "title_dic = defaultdict(list)\n",
    "title_cnt_dic ={}\n",
    "\n",
    "link_dic =defaultdict(list)\n",
    "link_cnt_dic = {}\n",
    "\n",
    "words_dic = {}\n",
    "\n",
    "tags = {'title': 0, 'text': 1, 'category': 2,'infobox':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.781467Z",
     "start_time": "2020-11-11T11:39:34.774454Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean():\n",
    "    text_cnt_dic ={}\n",
    "    category_cnt_dic ={}\n",
    "    infobox_cnt_dic ={}\n",
    "    title_cnt_dic ={}\n",
    "    link_cnt_dic = {}\n",
    "    words_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.787452Z",
     "start_time": "2020-11-11T11:39:34.783430Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean2():\n",
    "    text_dic = defaultdict(list)\n",
    "    category_dic =defaultdict(list)\n",
    "    infobox_dic =defaultdict(list)\n",
    "    title_dic = defaultdict(list)\n",
    "    link_dic = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.816340Z",
     "start_time": "2020-11-11T11:39:34.788416Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = {}\n",
    "stemmer = SnowballStemmer(language = 'english',ignore_stopwords=True)\n",
    "\n",
    "\n",
    "with open('data/stopwords.txt','r') as file:\n",
    "    words = file.read().split('\\n')\n",
    "    for word in  words:\n",
    "        word = stemmer.stem(word.lower())\n",
    "        stopwords[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.823323Z",
     "start_time": "2020-11-11T11:39:34.817367Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(s,tag):\n",
    "    if s:\n",
    "        words = re.split('[^A-Za-z0-9]', s)\n",
    "        for word in words:\n",
    "            word = stemmer.stem(word.lower())\n",
    "            if len(word)>=2:\n",
    "                words_dic[word]=1\n",
    "                if(tag=='title'):\n",
    "                    if word in title_cnt_dic:\n",
    "                        title_cnt_dic[word]+=1\n",
    "                    else :\n",
    "                        title_cnt_dic[word]=1\n",
    "                elif tag=='text':\n",
    "                    if word in infobox_cnt_dic:\n",
    "                        text_cnt_dic[word]+=1\n",
    "                    else :\n",
    "                        text_cnt_dic[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.835322Z",
     "start_time": "2020-11-11T11:39:34.824340Z"
    }
   },
   "outputs": [],
   "source": [
    "#done\n",
    "def category_updater(text):\n",
    "    rex = re.findall(\"\\[\\[Category:(.*?)\\]\\]\", str(text))\n",
    "    if rex:\n",
    "      #  print(rex)\n",
    "        for words in rex:\n",
    "          #  print(words)\n",
    "            #words = words.split(' ')\n",
    "            pattern = re.compile(\"[^a-zA-Z0-9]\")\n",
    "            words = re.split(pattern, words)\n",
    "            for word in words:\n",
    "              #  print(word)\n",
    "                word = stemmer.stem(word.lower())\n",
    "                if len(word)>1:\n",
    "                    words_dic[word]=1 \n",
    "                    if word in category_cnt_dic:\n",
    "                        category_cnt_dic[word]+=1\n",
    "                    else :\n",
    "                        category_cnt_dic[word]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.842296Z",
     "start_time": "2020-11-11T11:39:34.836311Z"
    }
   },
   "outputs": [],
   "source": [
    "#done\n",
    "def infobox_updater(s):\n",
    "    tempword = re.findall(\"{{Infobox((.|\\n)*?)}}\", str(s)) # get all data between infobox{{ ----- }}\n",
    "    if tempword :\n",
    "        for temp in tempword :\n",
    "            for word in temp : \n",
    "                pattern = re.compile(\"[^a-zA-Z0-9]\")\n",
    "                temp = re.split(pattern, word)\n",
    "                for t in temp :\n",
    "                    t = stemmer.stem(t.lower())\n",
    "                    if t :\n",
    "                        if len(t) <= 2 :\n",
    "                            continue\n",
    "                        if  t not in stopwords :\n",
    "                            words_dic[t]=1\n",
    "                            if t not in infobox_cnt_dic :\n",
    "                                infobox_cnt_dic[t] = 1\n",
    "                            else :\n",
    "                                infobox_cnt_dic[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T11:39:34.849253Z",
     "start_time": "2020-11-11T11:39:34.843268Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_no =0\n",
    "doc_cnt = 0\n",
    "\n",
    "doc_titles = open('doc_title.txt','a',encoding= 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T13:06:21.938628Z",
     "start_time": "2020-11-11T11:39:34.851246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 1\n",
      "text 1\n",
      "cat 1\n",
      "info 1\n",
      "title 2\n",
      "text 2\n",
      "cat 2\n",
      "info 2\n",
      "title 3\n",
      "text 3\n",
      "cat 3\n",
      "info 3\n",
      "title 4\n",
      "text 4\n",
      "cat 4\n",
      "info 4\n",
      "title 5\n",
      "text 5\n",
      "cat 5\n",
      "info 5\n",
      "title 6\n",
      "text 6\n",
      "cat 6\n",
      "info 6\n",
      "title 7\n",
      "text 7\n",
      "cat 7\n",
      "info 7\n",
      "title 8\n",
      "text 8\n",
      "cat 8\n",
      "info 8\n",
      "title 9\n",
      "text 9\n",
      "cat 9\n",
      "info 9\n",
      "title 10\n",
      "text 10\n",
      "cat 10\n",
      "info 10\n",
      "title 11\n",
      "text 11\n",
      "cat 11\n",
      "info 11\n",
      "title 12\n",
      "text 12\n",
      "cat 12\n",
      "info 12\n",
      "title 13\n",
      "text 13\n",
      "cat 13\n",
      "info 13\n",
      "title 14\n",
      "text 14\n",
      "cat 14\n",
      "info 14\n",
      "title 15\n",
      "text 15\n",
      "cat 15\n",
      "info 15\n",
      "title 16\n",
      "text 16\n",
      "cat 16\n",
      "info 16\n",
      "title 17\n",
      "text 17\n",
      "cat 17\n",
      "info 17\n",
      "title 18\n",
      "text 18\n",
      "cat 18\n",
      "info 18\n",
      "986\n",
      "title 19\n",
      "text 19\n",
      "cat 19\n",
      "info 19\n",
      "360986\n"
     ]
    }
   ],
   "source": [
    "file_no =1\n",
    "for i in range(len(XML_file_names)):\n",
    "    for event,element in ET.iterparse('current/'+XML_file_names[i],events=(\"start\",\"end\")):\n",
    "\n",
    "        tag = element.tag\n",
    "        #print(tag)\n",
    "        tag = tag[tag.rfind('}')+1:] #namespace\n",
    "\n",
    "        if tag == 'page' and event =='end':  #one page at a time\n",
    "\n",
    "            for w in words_dic:\n",
    "                #w = remove_special_characters(w)\n",
    "                for t in tags:\n",
    "                    if t=='title':\n",
    "                        if w in title_cnt_dic :\n",
    "                            s = \" \"+ str(doc_no)+\":\" + str(title_cnt_dic[w])\n",
    "                            title_dic[w].append(s)\n",
    "                    elif t=='text':\n",
    "                        if w in text_cnt_dic:\n",
    "                            s = \" \"+ str(doc_no)+\":\" + str(text_cnt_dic[w])\n",
    "                            text_dic[w].append(s)\n",
    "                    elif t=='category':\n",
    "                        if w in category_cnt_dic:\n",
    "                            s = \" \"+ str(doc_no)+\":\" + str(category_cnt_dic[w])\n",
    "                            category_dic[w].append(s)\n",
    "                    elif t=='infobox':\n",
    "                        if w in infobox_cnt_dic:\n",
    "                            s = \" \"+ str(doc_no)+\":\" + str(infobox_cnt_dic[w])\n",
    "                            infobox_dic[w].append(s)\n",
    "            doc_no+=1\n",
    "            doc_cnt+=1\n",
    "            element.clear()\n",
    "            title_cnt_dic.clear()\n",
    "            text_cnt_dic.clear()\n",
    "            category_cnt_dic.clear()\n",
    "            infobox_cnt_dic.clear()\n",
    "            words_dic.clear()\n",
    "        elif tag =='title' and event =='end':\n",
    "            text = element.text\n",
    "            text.strip()\n",
    "            text.replace(\" \",\"_\")\n",
    "            text = re.sub(\"\\s+\", \"_\", text.strip())\n",
    "            doc_titles.write(str(text)+'\\n')\n",
    "            update(str(text),tag)\n",
    "        elif tag =='text' and event =='end':\n",
    "                text = str(element.text)\n",
    "                text = regExp1.sub('',text)\n",
    "                text = regExp2.sub('',text)\n",
    "                text = regExp3.sub('',text)\n",
    "                text = regExp4.sub('',text)\n",
    "                update(str(text),tag)\n",
    "                category_updater(str(text))\n",
    "                infobox_updater(str(text))\n",
    "\n",
    "        if doc_cnt>=20000:\n",
    "            doc_cnt=0\n",
    "            title_path = 'final/title/' + str(file_no) +'.txt'\n",
    "            \n",
    "            file = open(title_path,'w',encoding='utf-8')\n",
    "            s= \"\"\n",
    "            for word in sorted(title_dic):\n",
    "                s= word + ' '\n",
    "                for vl in title_dic[word]:\n",
    "                    s+= vl +' '\n",
    "                s+= '\\n'\n",
    "                file.write(s)\n",
    "            file.close()\n",
    "            title_dic.clear()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            print('title',file_no)\n",
    "\n",
    "            text_path = 'final/text/' + str(file_no) +'.txt'\n",
    "            file = open(text_path,'w',encoding='utf-8')\n",
    "            s= \"\"\n",
    "            for word in sorted(text_dic):\n",
    "                s= word + ' '\n",
    "                for vl in text_dic[word]:\n",
    "                    s+= vl +' '\n",
    "                s+= '\\n'\n",
    "                file.write(s)\n",
    "            file.close()\n",
    "            \n",
    "            text_dic.clear()\n",
    "            \n",
    "            print('text',file_no)\n",
    "\n",
    "            cat_path = 'final/category/' + str(file_no) +'.txt'\n",
    "            file = open(cat_path,'w',encoding='utf-8')\n",
    "            s= \"\"\n",
    "            for word in sorted(category_dic):\n",
    "                s= word + ' '\n",
    "                for vl in category_dic[word]:\n",
    "                    s+= vl +' '\n",
    "                s+= '\\n'\n",
    "                file.write(s)\n",
    "            file.close()\n",
    "            \n",
    "            category_dic.clear()\n",
    "            \n",
    "            \n",
    "            print('cat',file_no)\n",
    "\n",
    "            info_path = 'final/infobox/' + str(file_no) +'.txt'\n",
    "            file = open(info_path,'w',encoding='utf-8')\n",
    "            s= \"\"\n",
    "            for word in sorted(infobox_dic):\n",
    "                s= word + ' '\n",
    "                for vl in infobox_dic[word]:\n",
    "                    s+= vl +' '\n",
    "                s+= '\\n'\n",
    "                file.write(s)\n",
    "            file.close()\n",
    "            \n",
    "            infobox_dic.clear()\n",
    "\n",
    "            print('info',file_no)\n",
    "            file_no+=1\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "if doc_cnt>0:\n",
    "    print(doc_cnt)\n",
    "    doc_cnt=0\n",
    "    #file_no = doc_no%5000 + 1\n",
    "    \n",
    "    title_path = 'final/title/' + str(file_no) +'.txt'\n",
    "    \n",
    "    file = open(title_path,'w',encoding='utf-8')\n",
    "    s= \"\"\n",
    "    for word in sorted(title_dic):\n",
    "        s= word + ' '\n",
    "        for vl in title_dic[word]:\n",
    "            s+= vl +' '\n",
    "        s+= '\\n'\n",
    "        file.write(s)\n",
    "    file.close()\n",
    "    print('title',file_no)\n",
    "    \n",
    "    title_dic.clear()\n",
    "\n",
    "    text_path = 'final/text/' + str(file_no) +'.txt'\n",
    "    file = open(text_path,'w',encoding='utf-8')\n",
    "    s= \"\"\n",
    "    for word in sorted(text_dic):\n",
    "        s= word + ' '\n",
    "        for vl in text_dic[word]:\n",
    "            s+= vl +' '\n",
    "        s+= '\\n'\n",
    "        file.write(s)\n",
    "    file.close()\n",
    "    \n",
    "    text_dic.clear()\n",
    "\n",
    "    print('text',file_no)\n",
    "\n",
    "    cat_path = 'final/category/' + str(file_no) +'.txt'\n",
    "    file = open(cat_path,'w',encoding='utf-8')\n",
    "    s= \"\"\n",
    "    for word in sorted(category_dic):\n",
    "        s= word + ' '\n",
    "        for vl in category_dic[word]:\n",
    "            s+= vl +' '\n",
    "        s+= '\\n'\n",
    "        file.write(s)\n",
    "    file.close()\n",
    "    \n",
    "    category_dic.clear()\n",
    "\n",
    "    print('cat',file_no)\n",
    "\n",
    "    info_path = 'final/infobox/' + str(file_no) +'.txt'\n",
    "    file = open(info_path,'w',encoding='utf-8')\n",
    "    s= \"\"\n",
    "    for word in sorted(infobox_dic):\n",
    "        s= word + ' '\n",
    "        for vl in infobox_dic[word]:\n",
    "            s+= vl +' '\n",
    "        s+= '\\n'\n",
    "        file.write(s)\n",
    "    file.close()\n",
    "    \n",
    "    infobox_dic.clear()\n",
    "\n",
    "    print('info',file_no)\n",
    "    file_no +=1\n",
    "    clean2()        \n",
    "\n",
    "print(doc_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
